Lox is a scripting language, which means it executes directly from source. Our interpreter will support two ways of running code. If you start jlox from the command line and give it a path to a file, it'll read the file and execute it. It will do this using the `runFile()` method established in our lox Java class. You can also run it interactively by running jlox w/o any arguments, and it'll drop you into a prompt where you can enter and execute code one line at a time. This interactive prompt system is also called a REPL, as it will **R**ead a line of input, **E**valuate it, **P**rint the result, and **L**oop to do it all over again.

Error handling will be done with a `errror()` function that calls a `report()` helper function to tel the user some syntax error occurred on a given line. We're gonna use the `hadError` boolean to ensure we don't try to execute code that has a known error. It also lets us exit with a non-zero exit code.

## Lexemes and Tokens

ex. `var language = "lox";`
Here, `var` is a keyword for declaring a variable. That three letter sequence "v-a-r" means something. But if we yank three letters out of the middle of language, like "g-u-a" it doesn't mean anything. This is what lexical analysis is about. We need to scan through the characters and group them into the smallest possible sequences that still represent something. Each of these groups is called a lexeme. 
ex. `[var] [language [=] ["lox"][;]`
The lexemes are only the raw substrings of source code. However, in grouping character sequences into lexemes, we stumble upon some other useful information. When we take the lexeme and group it together with other data, the result is a token. Tokens contain useful stuff like:

### Token type
Keywords are a part of the shape of the languages grammar, so the parser often has code like "If the next token is `while` then doâ€¦" That means the parser doesn't just want to know it has a lexeme for some identifier, but that it has a reserved word, and which keyword that is.

Instead of making the parser categorize tokens from raw lexemes using string comparison, we'll have the scanner classify lexemes.

### Literal value
These are lexemes for literal values, like numbers and strings. Because the scanner has to go through every character in the literal just to identify it, it can also convert that textual representation to the runtime object that will be used by the interpreter later. Basically this will allow for the scanner to assign literal values at compile time.

### Location information
We need to tell users where errors occurred. That tracking starts here, in this interpreter we don't just note the line the token appears on, but more sophisticated implementations include the column and length too.

We take all this info and wrap it into a class that we call a token.

## Regular Languages and Expressions
The core of a scanner is a loop. Starting at the first character of the source code, the scnner figures out what lexeme the character belongs to, and consumes it and any following characters that are part of that lexeme. When it reaches the end of the lexeme it emits a token. Then it loops back and repeats.

The rules that determine how a particular language groups character into lexemes are called its lexical grammar. In Lox, the rules of grammar are simple enough for the language to be classified a regular language.

You very precisely can recognize all of the different lexemes for Lox using regexes if you want to. 

We're going to do this using a scanner class that creates an arraylist of tokens, that takes in a String of source code, and converts the lexemes into tokens. This scanner class will have a `scanTokens` method that loops through the end of each lexeme and creates a token for each one.

This scanTokens will create a loop that scans each token, using an advance method that consumes the next character in the source file and returns it to a scanToken function that classifies it using regex string matching. This can be done easily using a match function.

So far this would work for single-character lexemes. However, that doesn't cover all of Lox's operators. What about `!`? It's a single character, but if the very next characters is an equals sign, we then need to create a `!=` lexeme. The exclamation point and the equals sign aren't independent operators, that's why we need to scan them both as a single lexeme. Likewise, `<`, `>`, and `=` can all be followed by `=` to create the other equality/comparison operators. for all of these, we need to look at the second character. We can do this by making a `peek()` method that looks at the next character without consuming it. We can then use this to make a method that checks the next character against some expected character. We can handle string literals by using this peek function in tandem with our advance function to check if a quote `"` closes before we advance, so we can grab every character after the start quote and before the end quote.

Numbers are a bit different as we're gonna initialize a number literal lexeme the moment we find a digit. It'd be rough to initialize every single number in the match function, so instead we're just gonna put an if statement in the default case to check for digits. We'll also make our own isDigit function, because apparently the native java isDigit allows for devanari digits and other stuff we can't accept. We're gonna do the same thing we did for strings now, just looping through the digits until we hit the end, or a decimal place, in which case we check to see if there's numbers for us to loop through after, then loop through those if there is.

These notes are kind of for me to explain this stuff to myself, and I don't know why but I just realized us making "start = current;" every single time we scan a new token allows us to process each lexeme. I was so confused trying to figure out why it wasn't processing from the beginning each time and forgot this line was even in the code shown in the book.